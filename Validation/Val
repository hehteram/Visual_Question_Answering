import numpy as np
import pickle
import tensorflow as tf
import h5py
from tensorflow.contrib import rnn

features = h5py.File('./Dataset/data_img_pool5.h5', 'r')
features = features['images_test']

answers_index = pickle.load(open("./Result/Answers_Val", "rb"))
images_index = pickle.load(open("./Result/Val_Question_Image", "rb"))
num2vec, questions = pickle.load(open("./Result/Question_Val", "rb"))

num_class = 1011
batch_size = 1464
sentence_len = 10
vec_len = 300
max_num = len(questions)
num_hidden = 1024
display_step = 20

Load = True

def newbatch(start_point):
    X_Image = []
    X_Question = []
    for i in range(start_point, start_point+batch_size):
        X_Image.append(np.transpose(features[images_index[i]], (1,2,0)))
        X_Question.append(tuple([num2vec[j] for j in questions[i]]))
    return tuple(X_Image), tuple(X_Question)


X_I = tf.placeholder("float", [batch_size, 7, 7, 512])
X_Q = tf.placeholder("float", [batch_size, sentence_len, vec_len])

cell = rnn.BasicLSTMCell(num_hidden)
cellout, cell_states = tf.nn.dynamic_rnn(cell, X_Q,dtype=tf.float32)

nm_X_I = tf.subtract(X_I,tf.tile(input=tf.reshape(tf.reduce_mean(X_I, axis=3), shape=(batch_size,7,7,1)), multiples=[1,1,1,512]))
X_I_L2 = tf.divide(nm_X_I, (tf.tile(tf.reshape(tf.sqrt(tf.reduce_sum(tf.multiply(nm_X_I,nm_X_I),axis=3)),shape=(batch_size,7,7,1)), multiples=[1,1,1,512])+1e-8))

C1 = tf.concat([X_I_L2, tf.tile(input=tf.reshape(tensor=cellout[:,9,:], shape=(batch_size,1,1,num_hidden)), multiples=[1,7,7,1])], axis=3)

dropout1 = tf.layers.dropout(inputs=C1, rate=0, training=False)

conv1 = tf.layers.conv2d(
      inputs = dropout1,
      filters=512,
      kernel_size=[1, 1],
      padding="same",
      activation=tf.nn.relu,
      bias_initializer = tf.constant_initializer(value=0.1),
      kernel_initializer= tf.random_normal_initializer(stddev=0.1))

dropout2 = tf.layers.dropout(inputs=conv1, rate=0, training=False)

conv2 = tf.layers.conv2d(
      inputs = dropout2,
      filters=2,
      kernel_size=[1, 1],
      padding="same",
      kernel_initializer=tf.random_normal_initializer(stddev=0.1))

r_X_I_L2 = tf.tile(tf.transpose(tf.reshape(tensor=X_I_L2, shape=(batch_size,49,1,512)), perm=[0,3,1,2]), multiples=[1,1,1,2])
attention = tf.tile(input=tf.nn.softmax(logits=tf.reshape(tensor=conv2, shape=(batch_size,1,49,2))), multiples=[1,512,1,1])
avg_w = tf.reshape(tf.reduce_sum(tf.transpose(tf.multiply(r_X_I_L2,attention),perm=[0,1,3,2]),axis=3),shape=(batch_size,num_hidden))

C2 = tf.concat([avg_w,tf.reshape(cellout[:,9,:],shape=[batch_size,num_hidden])], axis=1)

dropout3 = tf.layers.dropout(inputs=C2, rate=0, training=False)
dense1 = tf.layers.dense(inputs=dropout3, units=1024, activation=tf.nn.relu)

dropout4 = tf.layers.dropout(inputs=dense1, rate=0, training=False)
dense2 = tf.layers.dense(inputs=dropout4, units=num_class)

output = tf.nn.softmax(logits=dense2)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
saver = tf.train.Saver()
saver.restore(sess=sess, save_path='./new_Save2')

starter = 0
val_out = []
for iteration in range(0, 83):
    print(iteration)
    i, q= newbatch(starter)
    o = sess.run(output, feed_dict={X_I: i, X_Q: q})
    o = np.argmax(o, axis=1)
    for j in o:
        val_out.append(j)
    starter = starter + batch_size
pickle.dump(val_out, open("./Result/new_Prediction2", "wb"))
